{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment4-iteration2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApoorvaNagarajan/Image-Filter-Kernels/blob/master/assignment4/assignment4_iteration2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF2fiJhSIrco",
        "colab_type": "text"
      },
      "source": [
        "**Idea behind the network**\n",
        "\n",
        "- Has three improvements over iteration1\n",
        "- Improvements\n",
        "  - Reduce number of channels : To bring down number of parameters. Reducing such that we dont break our basic architectural idea of gradually increasing number of channels at convolution layers and reducing channels at the transition layer\n",
        "  - Increase batch size to 128 - To improve accuracy\n",
        "  - Add batch normalization to avoid overflow after every convolution layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjM9bxWOK__1",
        "colab_type": "text"
      },
      "source": [
        "**Observations : Filled after running the network below. (Have put it in the top so that this is not missed out)**\n",
        "\n",
        "- Parameters : 11,250\n",
        "- Epochs : 10\n",
        "- val_acc : 0.9879 - This is lesser than the first iteration\n",
        "- Time taken for each epoch : 120us\n",
        "- First two val_acc : 0.9782, 0.9764 : This is lesser than the DNN in 1st iteration. This implies that the accuracy will never match that of the first network usless other parameters are tweaked\n",
        "- With each iteration, training accuracy is increasing. But the testing accuracy is not. This means the network is over fitting\n",
        "- Number of parameters are good enough. I need to improve the accuracy keeping overfitting in mind in the next iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the required python libraries\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloads the MNIST dataset and splits it into test and train.\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# X_train and X_test are reshaped from 3 dimensions to 4 dimensions\n",
        "# 1st dim : num images\n",
        "# 2nd and 3rd dim : Width and height of eaach of the images\n",
        "# 4th dim : number of channels in each of the image. We set this to 1 as the\n",
        "#           our dataset has only gray images\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "\n",
        "# Normalizing the image\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "b154ca0b-e5fa-4982-cd6c-8ba8fa3fdd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) # receptive field: 3x3, output dim: 26x26x10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # receptive field: 5x5, output dim: 24x24x10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(20, 3, 3, activation='relu'))  # receptive field: 7x7, output dim: 22x22x20\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # receptive field: 14x14, output dim: 11x11x20\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) # receptive field: 14x14, output dim: 11x11x10\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # receptive field: 16x16, output dim: 9x9x10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(20, 3, 3, activation='relu')) # receptive field: 18x18, output dim: 7x7x20\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) # receptive field: 18x18, output dim: 7x7x10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 7)) # receptive field: 25x25, output dim: 1x1x10\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 22, 22, 20)        1820      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 20)        80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 10)        210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 20)          1820      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 20)          80        \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 7, 7, 10)          210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,250\n",
            "Trainable params: 11,070\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "fcb0990e-40c2-41f6-a066-0c17ade71dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, validation_data=(X_test, Y_test), verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.2390 - acc: 0.9272 - val_loss: 0.0696 - val_acc: 0.9782\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0588 - acc: 0.9821 - val_loss: 0.0766 - val_acc: 0.9764\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0417 - acc: 0.9873 - val_loss: 0.0420 - val_acc: 0.9863\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0341 - acc: 0.9892 - val_loss: 0.0383 - val_acc: 0.9883\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0337 - val_acc: 0.9895\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0423 - val_acc: 0.9863\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0343 - val_acc: 0.9893\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0189 - acc: 0.9942 - val_loss: 0.0380 - val_acc: 0.9890\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0504 - val_acc: 0.9843\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.0393 - val_acc: 0.9879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e25503f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "outputId": "868d46b1-c7e6-4117-fc3c-a7f302921778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03934841539740446, 0.9879]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}